!pip install pgmpy
from pgmpy.models import BayesianModel
from pgmpy.factors.discrete import TabularCPD

# Define the structure of the Bayesian Network
model = BayesianModel([('e', 'm'), ('i', 'm'), ('i', 's'), ('m', 'a')])

'''
                    Student
                      |
                      v
exam ---> marks <--- IQ
           |
           v
      admission
'''

# Define Conditional Probability Distributions (CPDs)

cpd_e = TabularCPD(variable='e', variable_card=2, values=[[0.6], [0.4]])
cpd_i = TabularCPD(variable='i', variable_card=2, values=[[0.7], [0.3]])
cpd_m = TabularCPD(variable='m', variable_card=2,
                   evidence=['e', 'i'],
                   values=[[0.9, 0.6, 0.7, 0.1],
                           [0.1, 0.4, 0.3, 0.9]],
                   evidence_card=[2, 2])
cpd_s = TabularCPD(variable='s', variable_card=2,
                   evidence=['i'],
                   values=[[0.95, 0.2],
                           [0.05, 0.8]],
                   evidence_card=[2])
cpd_a = TabularCPD(variable='a', variable_card=2,
                   evidence=['m'],
                   values=[[0.8, 0.1],
                           [0.2, 0.9]],
                   evidence_card=[2])

# Add CPDs to the model
model.add_cpds(cpd_e, cpd_i, cpd_m, cpd_s, cpd_a)

# Check if the model is consistent
print("Model is consistent:", model.check_model())

# Print CPDs
for cpd in model.get_cpds():
    print("CPD for {}: \n{}".format(cpd.variable, cpd))

# Doing exact inference using Variable Elimination
from pgmpy.inference import VariableElimination

infer = VariableElimination(model)

# Calculate the probability of admission given marks=1
print("\nProbability of admission given marks=1:")
print(infer.query(variables=['a'], evidence={'m': 1}).values[1])

# Calculate the probability of marks given exam=0 and IQ=1
print("\nProbability of marks given exam=0 and IQ=1:")
print(infer.query(variables=['m'], evidence={'e': 0, 'i': 1}).values)




Sure, let's break down the provided code step by step and explain each part in detail:

1. Installation of `pgmpy`:
   - The first line `!pip install pgmpy` is a command used in Jupyter notebooks to install packages from PyPI (Python Package Index).
   - It installs the `pgmpy` library, which stands for Probabilistic Graphical Models in Python.

2. Importing Libraries:
   - `from pgmpy.models import BayesianModel`: This line imports the `BayesianModel` class from the `pgmpy.models` module. BayesianModel is used to define Bayesian networks.
   - `from pgmpy.factors.discrete import TabularCPD`: This line imports the `TabularCPD` class from the `pgmpy.factors.discrete` module. TabularCPD is used to define Conditional Probability Distributions (CPDs).

3. Defining the Bayesian Network Structure:
   - `model = BayesianModel([('e', 'm'), ('i', 'm'), ('i', 's'), ('m', 'a')])`: This line defines the structure of the Bayesian Network using the BayesianModel class. It specifies the relationships between variables using directed edges. In this network, 'e' (exam) influences 'm' (marks), 'i' (IQ) influences 'm' and 's' (student status), and 'm' influences 'a' (admission).

4. Defining Conditional Probability Distributions (CPDs):
   - Conditional Probability Distributions (CPDs) are defined for each node in the Bayesian Network.
   - For example, `cpd_e` defines the CPD for the variable 'e' (exam), `cpd_i` for 'i' (IQ), `cpd_m` for 'm' (marks), `cpd_s` for 's' (student status), and `cpd_a` for 'a' (admission).
   - The values for the CPDs are specified based on domain knowledge or data. These values represent the conditional probabilities of each variable given its parents.

5. Adding CPDs to the Model:
   - `model.add_cpds(cpd_e, cpd_i, cpd_m, cpd_s, cpd_a)`: This line adds the defined CPDs to the Bayesian Network model.

6. Model Consistency Check:
   - `model.check_model()`: This method checks if the model is consistent, i.e., if the CPDs are correctly specified and satisfy the model structure.

7. Printing CPDs:
   - `model.get_cpds()`: This method retrieves all CPDs from the model.
   - The loop prints each CPD along with its variable and associated probabilities.

8. Exact Inference Using Variable Elimination:
   - `from pgmpy.inference import VariableElimination`: This line imports the `VariableElimination` class from the `pgmpy.inference` module. VariableElimination is used for exact inference in Bayesian Networks.
   - `infer = VariableElimination(model)`: This line creates a VariableElimination object with the defined Bayesian Network model.

9. Querying Probabilities:
   - `infer.query()`: This method is used to query the Bayesian Network for probabilities given evidence.
   - For example, `infer.query(variables=['a'], evidence={'m': 1})` calculates the probability of admission ('a') given marks=1.
   - Similarly, `infer.query(variables=['m'], evidence={'e': 0, 'i': 1})` calculates the probability of marks ('m') given exam=0 and IQ=1.

This code demonstrates the construction of a Bayesian Network, defining CPDs, adding them to the model, performing inference, and querying probabilities. It's a fundamental example of probabilistic graphical models, which are widely used in machine learning and artificial intelligence for modeling uncertainty and making predictions. Let me know if you need further clarification on any part!
'''

Certainly! Let me explain each line of the code to you:


from pgmpy.models import BayesianModel
from pgmpy.factors.discrete import TabularCPD
Here, we import the necessary classes from the pgmpy library. BayesianModel is used to define the structure of the Bayesian Network, and TabularCPD is used to define Conditional Probability Distributions (CPDs).


model = BayesianModel([('e', 'm'), ('i', 'm'), ('i', 's'), ('m', 'a')])
This line defines the structure of the Bayesian Network. Each tuple in the list represents a directed edge in the network. So, ('e', 'm') indicates a directed edge from node 'e' to node 'm', and so on.


cpd_e = TabularCPD(variable='e', variable_card=2, values=[[0.6], [0.4]])
This line defines the Conditional Probability Distribution (CPD) for the variable 'e', which represents the exam level. It specifies that there are two possible values for 'e' (variable_card=2), and the probabilities of these values are given as values=[[0.6], [0.4]].


cpd_i = TabularCPD(variable='i', variable_card=2, values=[[0.7], [0.3]])
Similar to the previous line, this defines the CPD for the variable 'i', which represents the IQ level.


cpd_m = TabularCPD(variable='m', variable_card=2,
                   evidence=['e', 'i'],
                   values=[[0.9, 0.6, 0.7, 0.1],
                           [0.1, 0.4, 0.3, 0.9]],
                   evidence_card=[2, 2])
This line defines the CPD for the variable 'm', which represents the marks. It specifies that 'm' depends on both 'e' and 'i' (as indicated by evidence=['e', 'i']). The values attribute specifies the probabilities of 'm' given different combinations of values for 'e' and 'i'.


cpd_s = TabularCPD(variable='s', variable_card=2,
                   evidence=['i'],
                   values=[[0.95, 0.2],
                           [0.05, 0.8]],
                   evidence_card=[2])
This line defines the CPD for the variable 's', which represents the aptitude score. It specifies that 's' depends on 'i' only.


cpd_a = TabularCPD(variable='a', variable_card=2,
                   evidence=['m'],
                   values=[[0.8, 0.1],
                           [0.2, 0.9]],
                   evidence_card=[2])
This line defines the CPD for the variable 'a', which represents the admission. It specifies that 'a' depends on 'm' (marks).


model.add_cpds(cpd_e, cpd_i, cpd_m, cpd_s, cpd_a)
Here, we add all the defined CPDs to the Bayesian Network model.


print("Model is consistent:", model.check_model())
This line checks if the model is consistent, meaning if all the CPDs are properly defined and the model structure is valid.


for cpd in model.get_cpds():
    print("CPD for {}: \n{}".format(cpd.variable, cpd))
This loop prints out all the CPDs defined in the model.


infer = VariableElimination(model)
This line initializes the Variable Elimination algorithm for inference on the Bayesian Network model.


print("\nProbability of admission given marks=1:")
print(infer.query(variables=['a'], evidence={'m': 1}).values[1])
Here, we perform inference to calculate the probability of admission given marks=1 using the Variable Elimination algorithm and print the result.


print("\nProbability of marks given exam=0 and IQ=1:")
print(infer.query(variables=['m'], evidence={'e': 0, 'i': 1}).values)
Similarly, this line calculates the probability of marks given exam=0 and IQ=1 and prints the result.



'''

Other code 

class BayesianNetwork:
    def __init__(self, cpt_a, cpt_m_given_ie, cpt_i, cpt_e):
        self.cpt_a = cpt_a
        self.cpt_m_given_ie = cpt_m_given_ie
        self.cpt_i = cpt_i
        self.cpt_e = cpt_e

    def joint_probability(self, a, m, i, e):
        return self.cpt_a[a] * self.cpt_m_given_ie[m][i][e] * self.cpt_i[i] * self.cpt_e[e]

cpt_a = {True: 0.7, False: 0.3}
cpt_m_given_ie = {
    100: {
        90: {True: 0.2, False: 0.3},
        80: {True: 0.1, False: 0.4}
    },
    90: {
        90: {True: 0.1, False: 0.4},
        80: {True: 0.3, False: 0.3}
    }
}
cpt_i = {90: 0.6, 100: 0.4}
cpt_e = {True: 0.5, False: 0.5}

bayesian_network = BayesianNetwork(cpt_a, cpt_m_given_ie, cpt_i, cpt_e)
joint_prob = bayesian_network.joint_probability(True, 100, 90, True)
print("Joint Probability:", joint_prob)






